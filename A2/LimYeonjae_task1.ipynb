{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AZKCMBf4c0t"
      },
      "source": [
        "# Individual Assignment 2 - Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vOrtaZbdNXK3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN9rcwfiNbmb"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U-8QO0OENZBC"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "iris_data = pd.read_csv(\"iris.data\", header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcHVM12sOPUH"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KI3qxHjiNa6r"
      },
      "outputs": [],
      "source": [
        "# Convert class labels to numerical values\n",
        "class_mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
        "iris_data[4] = iris_data[4].map(class_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dchQKsRDOSHz"
      },
      "source": [
        "## Stratified sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rl65VcNIKcwF"
      },
      "outputs": [],
      "source": [
        "# Stratified sampling for train-test split\n",
        "# Select ~70% for training and ~30% for test\n",
        "def stratified_sampling(data, test_ratio=0.3):\n",
        "    classes = data[4].unique()\n",
        "    test_indices = []\n",
        "    for cls in classes:\n",
        "        cls_indices = data[data[4] == cls].index\n",
        "        test_size = int(len(cls_indices) * test_ratio)\n",
        "        test_indices.extend(np.random.choice(cls_indices, test_size, replace=False))\n",
        "    train_indices = data.index.difference(test_indices)\n",
        "    return train_indices, test_indices\n",
        "\n",
        "train_indices, test_indices = stratified_sampling(iris_data)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = iris_data.iloc[train_indices]\n",
        "test_data = iris_data.iloc[test_indices]\n",
        "\n",
        "# Separate features and labels\n",
        "X_train, y_train = train_data.iloc[:, :-1], train_data.iloc[:, -1]\n",
        "X_test, y_test = test_data.iloc[:, :-1], test_data.iloc[:, -1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpsCvcRKOY0L"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JYu1_5m8OBCT"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes Classifier\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self):\n",
        "        self.class_probs = None\n",
        "        self.feature_probs = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.classes = np.unique(y)\n",
        "        n_classes = len(self.classes)\n",
        "\n",
        "        # Calculate class probabilities\n",
        "        self.class_probs = np.zeros(n_classes)\n",
        "        for i, cls in enumerate(self.classes):\n",
        "            self.class_probs[i] = np.sum(y == cls) / n_samples\n",
        "\n",
        "        # Calculate feature probabilities\n",
        "        self.feature_probs = []\n",
        "        for cls in self.classes:\n",
        "            cls_data = X[y == cls]\n",
        "            cls_feature_probs = []\n",
        "            for feature in range(n_features):\n",
        "                feature_mean = np.mean(cls_data[:, feature])\n",
        "                feature_std = np.std(cls_data[:, feature])\n",
        "                cls_feature_probs.append((feature_mean, feature_std))\n",
        "            self.feature_probs.append(cls_feature_probs)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for x in X:\n",
        "            cls_probs = []\n",
        "            for i, cls in enumerate(self.classes):\n",
        "                cls_prob = np.log(self.class_probs[i])\n",
        "                for j, feature in enumerate(x):\n",
        "                    mean, std = self.feature_probs[i][j]\n",
        "                    cls_prob += np.log(self.gaussian_prob(feature, mean, std))\n",
        "                cls_probs.append(cls_prob)\n",
        "            preds.append(np.argmax(cls_probs))\n",
        "        return preds\n",
        "\n",
        "    @staticmethod\n",
        "    def gaussian_prob(x, mean, std):\n",
        "        exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
        "        return (1 / (np.sqrt(2 * np.pi) * std)) * exponent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEsoQYEwOeIC"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huxQz7p-OC4Q",
        "outputId": "0a25307f-112d-4216-b464-f8e4954234d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set Accuracy: 0.9523809523809523\n",
            "Test set Accuracy: 0.9777777777777777\n"
          ]
        }
      ],
      "source": [
        "# Train the Naive Bayes classifier\n",
        "nb_classifier = NaiveBayesClassifier()\n",
        "nb_classifier.fit(X_train.values, y_train.values)\n",
        "\n",
        "# Train set\n",
        "train_pred = nb_classifier.predict(X_train.values)\n",
        "train_accuracy = np.mean(train_pred == y_train.values)\n",
        "print(\"Train set Accuracy:\", train_accuracy)\n",
        "\n",
        "# Test set\n",
        "test_pred = nb_classifier.predict(X_test.values)\n",
        "accuracy = np.mean(test_pred == y_test.values)\n",
        "print(\"Test set Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result:\n",
        "* The Naive Bayes Classifier achieves a training set accuracy of approximately **95.24%** and a test set accuracy of approximately **97.78%**. These results indicate that the classifier generalizes well to unseen data, demonstrating its effectiveness in accurately classifying Iris flower samples based on their features.\n",
        "\n",
        "### Conclusion:\n",
        "* In conclusion, the implementation of the Gaussian Naive Bayes Classifier demonstrates the effectiveness of the algorithm in handling classification tasks, particularly with datasets containing continuous features following Gaussian distributions. By leveraging the principles of Bayes' theorem and assuming feature independence, the classifier provides a simple yet robust solution for classification problems."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
